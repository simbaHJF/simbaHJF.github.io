---
layout:     post
title:      "消息队列--Kafka如何实现高性能IO"
date:       2019-10-27 14:00:00 +0800
author:     "simba"
header-img: "img/post-bg-miui6.jpg"
tags:
    - MQ

---

> 极客时间--李玥--消息队列高手课 学习笔记

##	使用批量消息提升服务端处理能力

批处理是一种非常有效的提升系统吞吐量的方法.在Kafka内部,消息都是以"批"为单位处理的.Kafka的客户端SDK中,Kafka的Producer只提供了单条发送的send()方法,并没有提供任何批量发送的接口.原因是,Kafka根本就没有提供单条发送的功能,虽然它提供的API每次只能发送一条消息,但实际上,Kafka的客户端SDK在实现消息发送逻辑的时候,采用了异步批量发送的机制.当调用send()方法发送一条消息之后,无论是同步发送还是异步发送,Kafka都不会立即就把这条消息发送出去.它会先把这条消息,存放在内存中缓存起来,然后选择合适的时机把缓存中的消息组成一批,一次性发给Broker.简单讲,就是攒一波一起发.

在Kafka的服务端,也就是Broker这一端,又是如何处理这一批一批的消息的呢?

在服务端,Kafka不会把一批消息再还原成多条消息,再一条一条地处理,这样太慢了.Kafka会把每批消息都当做一个"批消息"来处理.也就是说,在Broker整个处理流程中,无论是写入磁盘,从磁盘读出来,还是复制到其他副本这些流程中,*批消息都不会被解开,一直是作为一条"批消息"来进行处理的.*

在消费时,消息同样是以批为单位进行传递的,Consumer从Broker拉到一批消息后,在客户端把批消息解开,在一条一条交给用户代码处理.

构建批消息和解开批消息分别在发送端和消费端的客户端完成,不仅减轻了Broker的压力,最重要的是减少了Broker处理请求的次数,提升了总体的处理能力.

这就是Kafka用批量消息提升性能的方法.

相比于网络传输和内存,磁盘IO的速度是比较慢的.对于消息队列的服务端来说,性能的瓶颈主要在磁盘IO这一块.下面来看一下Kafka在磁盘IO这块做了哪些优化


##	使用顺序读写提升磁盘IO性能

对于磁盘来说,顺序读写的性能要远远好于随机读写.Kafka充分利用了磁盘的这个特性.它的存储设计非常简单,对于每个分区,他把从Producer收到的消息,顺序地写入对应的log文件中,一个文件写满了,就开启一个新的文件这样顺序写下去.消费的时候,也是从某个全局的位置开始,也就是某一个log文件中的某个位置开始,顺序地把消息读出来.

这样一个简单的设计,充分利用了顺序读写这个特性,极大提升了Kafka在使用磁盘时的IO性能.


##	利用PageCache加速消息读写

在Kafka中,它会利用PageCache加速消息读写.PageCache是现代操作系统都具有的一项基本特性.通俗地说,PageCache就是操作系统在内存中给磁盘上的文件建立的缓存.无论使用什么语言编写程序,在调用系统的API读写文件的时候,并不会直接去读写磁盘上的文件,应用程序实际操作的都是PageCache,也就是文件在内存中缓存的副本.应用程序在写入文件的时候,操作系统会先把数据写入到内存中的PageCache,然后再一批一批地写到磁盘上.读取文件的时候,也是从PageCache中来读取数据,这时候会出现两种情况.

一种是PageCache中有数据,那就直接读取,这样就节省了从磁盘上读取数据的时间;另一种情况是,PageCache中没有数据,这时候操作系统会引发一个缺页中断,应用程序的读取线程会被阻塞,操作系统把数据从文件中复制到PageCache中,然后应用程序再从PageCache中继续把数据读出来,这时会真正读取一次磁盘上的文件,这个读的过程就会比较慢.

用户的应用程序在使用完某块PageCache后,操作系统并不会立刻就清除这个PageCache,而是尽可能地利用空闲的物理内存保存这些PageCache,除非系统内存不够用,操作系统才会清理掉一部分PageCache.清理的策略一般是LRU或它的变种算法.

Kafka在读写消息文件的时候,充分利用了PageCache的特性.一般来说,消息刚刚写入到服务端就会被消费,按照LRU的"优先清除最近最少使用的页"这种策略,读取到的时候,对于这种刚刚写入的PageCache,命中的几率会非常高.也就是说,在大部分情况下,消费者读消息都会命中PageCache,带来的好处有两个:一个是读取的速度会非常快,另一个是,给写入消息让出磁盘的IO资源,间接页提升了写入的性能.


##	ZeroCopy:零拷贝技术

Kafka的服务端在消费过程中,还是用了一种"零拷贝"的操作系统特性来进一步提升消费的性能.

在服务端,处理消费的大致逻辑是这样的:

*	首先,从文件中找到消息数据,读到内存中;
*	然后,把消息通过网络发给客户端.

这个过程中,数据实际上做了2次或3次复制:

1.	从文件复制数据到PageCache中,如果命中PageCache,这一步可以省掉;
2.	从PageCache复制到应用程序的内存空间中,也就是我们可以操作的对象所在的内存(内和空间到用户空间的拷贝);
3.	从应用程序的内核空间复制到Socket的缓冲区,这个过程就是我们调用网络应用框架的API发送数据的过程.

Kafka使用零拷贝技术可以把这个复制次数减少一次,上面的2,3步骤两次复制合并成一次复制.直接从PageCache中把数据复制到Socket缓冲区,这样不仅减少一次数据复制,更重要的是,由于不用把数据复制到用户内存空间,DMA控制器可以直接完成数据复制,不需要CPU参与,速度更快.

下面是这个零拷贝对应的系统调用:
```
#include <sys/socket.h>
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
```

sendfile系统调用有一点需要注意的是,它不能对数据进行修改.

如果你遇到这种从文件读取数据后在通过网络发送出去的场景,并且这个过程中你不需要对这些数据进行处理,那一定要使用这个零拷贝的方法,可以有效的提升性能.