---
layout:     post
title:      "kafka 日志存储"
date:       2021-06-01 12:30:00 +0800
author:     "simba"
header-img: "img/post-bg-miui6.jpg"
tags:
    - MQ

---




## 导航
[一. 文件目录布局](#jump1)
<br>
[二. 压缩消息](#jump2)
<br>
[三. 日志索引](#jump3)
<br>
[四. 磁盘存储及读写性能优化](#jump4)
<br>









<br><br>
## <span id="jump1">一. 文件目录布局</span>

<br>
**<font size="4">分区主题日志逻辑结果图</font>** <br>

[![2ncy79.png](https://z3.ax1x.com/2021/06/01/2ncy79.png)](https://imgtu.com/i/2ncy79)

Log对应了一个命名形式为\<topic\>-\<partition\>的文件夹。举个例子，假设有一个名为“topic-log”的主题，此主题中具有 4 个分区，那么在实际物理存储上表现为“topic-log-0”, “topic-log-1”, “topic-log-2”, “topic-log-3” 这4个文件夹. <br>

向Log中追加消息时是顺序写入的,满足一定条件下(主要是LogSegment大小达到阈值或者索引文件大小达到阈值,当然还有一些其他成立条件),会创建一个新的LogSegment,只有当前最新LogSegment可供写入,其他的LogSegment都只能做读取用.<br>

kafka常用文件:
* .log文件 ----- 对应消息数据日志文件
* .index文件 ----- 偏移量索引文件,用来建立消息偏移量到物理地址之间的映射关系,方便快速定位消息所在的物理文件位置
* .timeindex ----- 时间戳索引文件,根据时间戳来查找对应的偏移量

每个 LogSegment 都有一个基准偏移量 baseOffset，用来表示当前 LogSegment 中第一条消息的offset.偏移量是一个64位的长整型数，日志文件和两个索引文件都是根据基准偏移量(baseOffset)命名的，名称固定为20 位数字，没有达到的位数则用 0 填充.  比如第一个 LogSegment 的基准偏移量为 0，对应的日志文件为 00000000000000000000.logo。如某一时刻,topic-log-0目录中的布局如下:

[![2nWaE4.png](https://z3.ax1x.com/2021/06/01/2nWaE4.png)](https://imgtu.com/i/2nWaE4)

这里需要说明一点,每个 LogSegment 中不只包含前面说的三种文件,还可能包含一些其他文件.有关其他文件这里先暂不深入说.<br>



<br><br>
## <span id="jump2">二. 压缩消息</span>

常见的压缩算法是数据量越大压缩效果越好,一条消息通常不会太大,这就导致压缩效果并不是太好.而 Kafka 实现的压缩方式是将多条消息一起进行压缩,这样可以保证较好的压缩效果.在一般情况下，生产者发送的压缩数据在 broker 中也是保持压缩状态进行存储的,消费 者从服务端获取的也是压缩的消息,消费者在处理消息之前才会解压消息,这样保持了端到端的压缩. <br>

kafka中有消息和消息集的概念,消息集中包含一条或多条消息,消息集不仅是存储于磁盘及在网络上传输(Produce & Fetch)的基本形式,而且是 Kafka 中压缩的基本单元.此处可回顾下kafka producer端的ProducerBatch和ProducerRecord概念. <br>

在单条消息发送,不压缩情况下,消息存储格式大致如下:
[![2nqtA0.png](https://z3.ax1x.com/2021/06/01/2nqtA0.png)](https://imgtu.com/i/2nqtA0)

如果kafka采用producer端批量发送消息,且开启压缩的话.消息压缩时是将整个消息集进行压缩作为内层消息 (inner message),内层消息整体作为外层( wrapper message) 的value,一个压缩消息(内含其实有多条消息记录)存储格式大致如下:
[![2nLsxg.png](https://z3.ax1x.com/2021/06/01/2nLsxg.png)](https://imgtu.com/i/2nLsxg)

外层对内层关系如下:
[![2nO3oq.png](https://z3.ax1x.com/2021/06/01/2nO3oq.png)](https://imgtu.com/i/2nO3oq)

每个从生产者发出的消息集中的消息 offset都是从 0开始的,当然这个 offset不能直接存储在日志文件中,对offset 的转换是在服务端进行的,客户端不需要做这个工作。外层消息保存了内层消息中最后一条消息的绝对位移 (absolute offset)，绝对位移是相对于整个分区而言的。<br>



<br><br>
## <span id="jump3">三. 日志索引</span>

Kafka 中的索引文件以稀疏索引(sparse index)的方式构造消息的索引,它并不保证每个消息在索引文件中都有对应的索引项. 每当写入一定量(由 broker 端参数 log.index.interval.bytes 指定,默认值为 4096，即 4KB)的消息时,偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项,增大或减小 log.index.interval.bytes 的值,对应地可以增加或缩小索引项的密度。<br>

稀疏索引通过 MappedByteBuffer将索引文件映射到内存中,以加快索引的查询速度。偏移量索引文件中的偏移量是单调递增的,查询指定偏移量时,使用二分查找法来快速定位偏移量
的位置,如果指定的偏移量不在索引文件中,则会返回小于指定偏移量的最大偏移量。时间戳索引文件中的时间戳也保持严格的单调递增,查询指定时间戳时,也根据二分查找法来查找不大于该时间戳的最大偏移量,至于要找到对应的物理文件位置还需要根据偏移量索引文件来进行再次定位.稀疏索引的方式是在磁盘空间、内存空间、查找时间等多方面之间的一个折中。

这里稍微总结下:
* 根据偏移量索引找消息过程如下:  偏移量索引 ----> 消息文件
* 根据时间戳索引找消息过程如下:  时间戳索引找到偏移量 ----> 偏移量索引找消息在log中的地址 ----> 消息文件


<br>
**<font size="5">偏移量索引</font>** <br>

每个索引项占用8个字节,分为两个部分:
* relativeOffset : 相对偏移量,表示消息相对于baseOffset的偏移量,占用4个字节,当前索引文件的文件名即为baseOffset的值
* position : 物理地址,也就是消息在日志分段文件中对应的物理位置,占用4个字节.

[![2up4v6.png](https://z3.ax1x.com/2021/06/01/2up4v6.png)](https://imgtu.com/i/2up4v6)

消息的偏移量(offset)占用 8 个字节,也可以称为绝对偏移量。索引项中没有直接使用绝对偏移量而改为只占用 4 个字节的相对偏移量 CrelativeOffset =offset - baseOffset)，这样可以减小索引文件占用的空间。<br>

索引偏移量示意图如下:
[![2uChnK.png](https://z3.ax1x.com/2021/06/01/2uChnK.png)](https://imgtu.com/i/2uChnK)

对照上图,这里来分析下要查找偏移量为23的消息流程:
1. 通过二分法在偏移量索引文件中找到不大于23的最大索引项,即[22,656]
2. 从日志分段文件中的物理位置656开始顺序查找偏移量为23的消息

下面再来看一个更全面的,例如有如下LogSegment文件:
[![2uimsP.png](https://z3.ax1x.com/2021/06/01/2uimsP.png)](https://imgtu.com/i/2uimsP)

这里先介绍一个kafka的优化: Kafka 的每个日志对象中使用了 ConcurrentSkipListMap 来保存各个日志分段,每个日志分段的 baseOffset 作为 key,这样可以根据指定偏移量来快速定位到消息所在的日志分段.结合跳表,要查找偏移量为268的消息流程如下:
1. 首先定位baseOffset为251的日志分段(LogSegment),这里会借助跳表
    > 这里得到了LogSegment文件,也就可以知道对应的.index文件了,因为他们的文件名都是baseOffset,只是索引文件的后缀为.index,用于存储偏移量映射
2. 计算相对偏移量 : relativeOffset = 268 - 251 = 17
3. 偏移量索引文件中二分查找不大于17的索引项
4. 根据找到的索引项获取position
5. 去LogSegment中position位置开始顺序查找偏移量为268的消息


<br>
**<font size="5">时间戳索引</font>** <br>

每个索引占用12个字节,分为两个部分:
* timestamp : 当前日志分段最大的时间戳
* relativeOffset : 时间戳所对应的消息的相对偏移量

[![2uVEuR.png](https://z3.ax1x.com/2021/06/01/2uVEuR.png)](https://imgtu.com/i/2uVEuR)

时间戳索引消息查找示意图:
[![2ueOjH.png](https://z3.ax1x.com/2021/06/01/2ueOjH.png)](https://imgtu.com/i/2ueOjH)

按时间戳查找就无法使用到跳表来快速定位了,它的流程如下:
1. 将 targetTimeStamp 和每个日志分段中的最大时间戳 largestTimeStamp逐一对比,直到找到不小于 targetTimeStamp 的 largestTimeStamp 所对应的日志分段,这一步完成后,找到了LogSegment文件
2. 由LogSegment文件知道了对应的时间戳索引文件
3. 从时间戳索引文件中二分查找不大于targetTimeStamp的最大索引项,如[1526384718283, 28],此时获得了偏移量28
4. 接下来就和前面按偏移量查找的步骤一样了



<br><br>
## <span id="jump4">四. 磁盘存储及读写性能优化</span>

<br>
**<font size="5">顺序写</font>** <br>

顺序写机制,包括消息数据文件(.log),偏移量索引文件(.index),时间戳索引文件(.timeindex)<br>


<br>
**<font size="5">页缓存</font>** <br>

依赖操作系统页缓存机制,避免过多的磁盘I/O


<br>
**<font size="5">磁盘I/O</font>** <br>

从编程角度而言,一般磁盘I/O的场景有以下四种:
* 用户调用标准 C 库进行 I/O 操作,数据流为 : 应用程序 buffer ---> C 库标准 IObuffer ---> 文件系统页缓存 ---> 通过具体文件系统到磁盘
* 用户调用文件 I/O, 数据流为 : 应用程序 buffer ---> 文件系统页缓存 ---> 通过具体文件系统到磁盘
* 用户打开文件时使用 O_DIRECT,绕过页缓存直接读写磁盘
* 用户使用类似 dd工具,并使用 direct参数,绕过系统 cache与文件系统直接写磁盘

磁盘I/O流程大体可描述为下图:
[![2uQC6O.png](https://z3.ax1x.com/2021/06/01/2uQC6O.png)](https://imgtu.com/i/2uQC6O)


<br>
**<font size="5">零拷贝</font>** <br>

MMap + (Sendfile + DMA gather copy)

* MMap : broker端用于接收producer端发来的消息,进行 .log文件, .index文件, .timeindex文件的顺序写和零拷贝直接内存映射
* sendfile : 用于consumer读消息时, 将消息数据从文件通过sendfile零拷贝直接把磁盘数据通过内核缓冲区+Socket(存放文件描述符,而并非全部数据)经由DMA送到网卡,避免了用户态的切换和拷贝.