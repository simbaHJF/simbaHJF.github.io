---
layout:     post
title:      "分布式系统--Paxos"
date:       2021-04-19 15:00:00 +0800
author:     "simba"
header-img: "img/post-bg-miui6.jpg"
tags:
    - 分布式

---








## 导航
[一. 经典Paxos算法要解决的问题](#jump1)
<br>
[二. Paxos算法的角色划分](#jump2)
<br>
[三. Proposer生成提案与Acceptor批准提案:Paxos算法描述](#jump3)
<br>
[四. 通过选取主Proposer保证算法的活性](#jump4)
<br>
[五. 一点总结](#jump5)
<br>









<br><br>
## <span id="jump1">一. 经典Paxos算法要解决的问题</span>

Paxos算法需要解决的问题是,如何在一个可能发生宕机或网络异常的分布式系统中,快速且正确地在集群内部对某个数据的值达成一致,并且保证不论发生以上任何异常,都不会破坏整个系统的一致性.<br>

<font color="red">这里某个数据的值并不只是狭义上的某个数,它可以是一条日志,也可以是一条命令,根据应用场景不同,某个数据的值有不同的含义.</font>



<br><br>
## <span id="jump2">二. Paxos算法的角色划分</span>

* Proposer:	提出提案  
* Acceptor:	接收提案  
* Learner:	复制Acceptor的状态(即Acceptor告诉Learner哪个Value被选定了)

在Paxos算法描述场景中,会有多个Proposer提出议案(也即数据),<font color="red">每个节点在协议中可以担任多个角色</font>.如下图所示
[![coRZ0f.png](https://z3.ax1x.com/2021/04/19/coRZ0f.png)](https://imgtu.com/i/coRZ0f)

图中5个server组成了Paxos算法集群,每个client都可以向server集群中的任意节点发送数据.这点是与Raft不同的,Raft中,只有leader节点可以接收写命令.<br>

在这个过程中,比如server1接收到了client的数据提交,那么此时server1将作为Proposer进行提出提案的操作,这时其他的server就作为Acceptor(这里包括server1,因此server1节点此时既作为Proposer提出提案,又作为Acceptor接受提案).<br>



<br><br>
## <span id="jump3">三. Proposer生成提案与Acceptor批准提案:Paxos算法描述</span>

<br>
**<font size="4">Proposer生成提案,也即阶段一</font>** <br>

1.	Proposer选择一个提案编号Mn,然后向Acceptor的某个超过半数的子集成员发送编号为Mn的Prepare请求.
2.	如果一个Acceptor收到一个编号为Mn的Prepare请求,且编号Mn大于该Acceptor已经响应的所有Prepare请求的编号,那么它就会将它已经批准过的最大编号的提案作为响应反馈给Proposer,同时该Acceptor会承诺不会再批准任何编号小于Mn的提案

在确定提案之后,Proposer就会将该提案在此发送给某个Acceptor集合,并期望获得它们的批准,我们称此请求为Accept请求.需要注意的一点是,此时接受Accept请求的Acceptor集合不一定是之前响应Prepare请求的Acceptor集合----这点相信读者也能够明白,任意两个半数以上的Acceptor集合,必定包含至少一个公共Acceptor.<br>


<br>
**<font size="4">Acceptor批准提案,也即阶段二</font>** <br>

1.	如果Proposer收到来自半数以上的Acceptor对于其发出的编号为Mn的Prepare请求的响应,那么它就会发送一个针对[Mn,Vn]提案的Accept请求给Acceptor.注意,Vn的值就是收到的响应中编号最大的提案的值,如果响应中不包含任何提案,那么它就是任意值.
2.	如果Acceptor收到这个针对[Mn,Vn]提案的Accept请求,只要该Acceptor尚未对编号大于Mn的Prepare请求做出响应,它就可以通过(批准)这个提案.



<br><br>
## <span id="jump4">四. 通过选取主Proposer保证算法的活性</span>

根据前面的内容讲解,我们已经基本上了解了Paxos算法的核心逻辑,下面我们再来看看Paxos算法在实际作过程中的一些细节.假设存在这样一种极端情况,有两个Proposer依次提出了一系列编号递增的议案,但是最终都无法被选定,具体流程如下:<br>

Proposer P1提出了一个编号为M1的提案,并完成了上述阶段一的流程.但与此同时,另外一个Proposer P2提出了一个编号为M2(M2>M1)的提案,同样也完成了阶段一的流程,于是Acceptor已经承诺不再批准编号小于M2的提案了.因此,当P1进入阶段二的时候,其发出的Accept请求将被Acceptor忽略,于是P1再次进入阶段一并提出了一个编号为M3(M3>M2)的提案,而这又导致P2在第二阶段的Accept请求被忽略,以此类推,提案的选定过程将陷入死循环.<br>

<font color="red">因此,原始经典base-paxos这种方案达成一件事情的一致性还好,面对多件事情的一致性就比较复杂了,所以通过选举出一个leader来简化实现的复杂性比较符合需求.</font> <br>

为了保证Paxos算法流程的可持续性,以避免陷入上述提到的"死循环",就必须选择一个主Proposer,并规定只有主Proposer才能提出议案.这样一来,只要主Proposer和过半的Acceptor能够正常进行网络通信,那么但凡主Proposer提出一个编号更高的提案,该提案终将会被批准.因此,如果系统中有足够多的组件(包括Proposer,Acceptor和其他网络通信组件)能够正常工作,那么通过选择一个主Proposer,整套Paxos算法流程就能够保持活性.<br>



<br><br>
## <span id="jump5">五. 一点总结</span>

Paxos的描述场景是,存在多个Proposer可以提出提案(可理解为发起分布式数据写入),因此,Paxos算法分为两个阶段,首先进行提案编号询问(也即阶段一,Proposer生成提案,发出prepare请求),阶段一成功后再进行阶段二(发出accept请求,Acceptor批准提案),但这里阶段二就会存在上面第四节描述的问题,因此阶段二不能确保一定成功,哪怕在网络良好未出现分区的情况下.<br>

而为了避免前面的这个问题,就提出了选主的思想(leader才能执行写入请求,也即Proposer变成了一个),此时就不会出现这个问题了,这时是不是就很像Raft了呢?对吧.<br>

Raft简化了场景,规定只允许存在一个节点能操作写入,即leader.对于leader可能的宕机而造成的单点问题,采用故障恢复的选主来进行故障转移,完美解决,同时实现起来逻辑清晰,界限分明,不像Paxos那么模糊复杂.<br>